{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3771b38f042d4ac098d85860e0c8c5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "import scipy.stats as ss\n",
    "from skimage.feature import local_binary_pattern\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "\n",
    "n_images = 4\n",
    "\n",
    "\n",
    "def get_noise_features(noise, prefix):\n",
    "    noise_features = {\n",
    "        prefix + '_mean': np.mean(noise),\n",
    "        prefix + '_std': np.std(noise),\n",
    "        prefix + '_median': np.median(noise),\n",
    "        prefix + '_min': np.min(noise),\n",
    "        prefix + '_max': np.max(noise),\n",
    "        prefix + '_sum': np.sum(noise),\n",
    "        prefix + '_kurtosis': ss.kurtosis(noise.flatten()),\n",
    "        prefix + '_skewness': ss.skew(noise.flatten()),\n",
    "        prefix + '_entropy': ss.entropy(noise.flatten()),\n",
    "        prefix + '_variation': ss.variation(noise.flatten()),\n",
    "        prefix + '_noises_zero_count': len(noise[noise == 0]),\n",
    "        prefix + '_non_zero_count': len(noise[noise > 0]),\n",
    "        prefix + '_non_zero_mean': np.mean(noise[noise > 0]),\n",
    "        prefix + '_non_zero_std': np.std(noise[noise > 0]),\n",
    "        prefix + '_non_zero_median': np.median(noise[noise > 0]),\n",
    "        prefix + '_nnon_zero_entropy': ss.entropy(noise[noise > 0].flatten()),\n",
    "        prefix + '_non_zero_variation': ss.variation(noise[noise > 0].flatten()),\n",
    "        prefix + '_low_value_count': (noise < 50).sum(),\n",
    "        prefix + '_high_value_count': (noise > 200).sum()\n",
    "    }\n",
    "    return noise_features\n",
    "\n",
    "\n",
    "def format_(name, values):\n",
    "    return {'{}{}'.format(name, i): v for i, v in enumerate(values)}\n",
    "\n",
    "def get_image_features(img, x1, y1, x2, y2):\n",
    "    img = img[x1:x2, y1:y2]\n",
    "\n",
    "    img_nl = cv2.fastNlMeansDenoisingColored(img)\n",
    "    noise_nl = img - img_nl\n",
    "    \n",
    "#     img_dw = denoise_wavelet(img, multichannel=True)\n",
    "#     noise_dw = img - (img_dw * 255).astype(np.int)\n",
    "\n",
    "    features = {}\n",
    "    features.update(get_noise_features(noise_nl[:,:,0], 'noise_nl_r'))\n",
    "    features.update(get_noise_features(noise_nl[:,:,1], 'noise_nl_g'))\n",
    "    features.update(get_noise_features(noise_nl[:,:,2], 'noise_nl_b'))\n",
    "\n",
    "#     features.update(get_noise_features(noise_dw[:,:,0], 'noise_dw_r'))\n",
    "#     features.update(get_noise_features(noise_dw[:,:,1], 'noise_dw_g'))\n",
    "#     features.update(get_noise_features(noise_dw[:,:,2], 'noise_dw_b'))\n",
    "\n",
    "    features.update(format_('noise_nl_hist_r', cv2.calcHist([noise_nl], [0], None, [256], [0, 256]).flatten()))\n",
    "    features.update(format_('noise_nl_hist_g', cv2.calcHist([noise_nl], [1], None, [256], [0, 256]).flatten()))\n",
    "    features.update(format_('noise_nl_hist_b', cv2.calcHist([noise_nl], [2], None, [256], [0, 256]).flatten()))\n",
    "\n",
    "#     features.update(format_('noise_dw_hist_r', cv2.calcHist([noise_dw], [0], None, [256], [0, 256]).flatten()))\n",
    "#     features.update(format_('noise_dw_hist_g', cv2.calcHist([noise_dw], [1], None, [256], [0, 256]).flatten()))\n",
    "#     features.update(format_('noise_dw_hist_b', cv2.calcHist([noise_dw], [2], None, [256], [0, 256]).flatten()))\n",
    "\n",
    "    features.update(format_('img_hist_r', cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()))\n",
    "    features.update(format_('img_hist_g', cv2.calcHist([img], [1], None, [256], [0, 256]).flatten()))\n",
    "    features.update(format_('img_hist_b', cv2.calcHist([img], [2], None, [256], [0, 256]).flatten()))\n",
    "\n",
    "    #Get LBP from image \n",
    "    lbp_r = local_binary_pattern(img[:,:,0], 8, 3)\n",
    "    lbp_g = local_binary_pattern(img[:,:,1], 8, 3)\n",
    "    lbp_b = local_binary_pattern(img[:,:,2], 8, 3)  \n",
    "    (hist_r, _) = np.histogram(lbp_r, bins=256)\n",
    "    (hist_g, _) = np.histogram(lbp_g, bins=256)\n",
    "    (hist_b, _) = np.histogram(lbp_b, bins=256)\n",
    "    features.update(format_('img_hist_lbp_r', hist_r))\n",
    "    features.update(format_('img_hist_lbp_g', hist_g))\n",
    "    features.update(format_('img_hist_lbp_b', hist_b))\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def get_path_features(path):\n",
    "    features_list = []\n",
    "    img = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    (h, w) = img.shape[:2]\n",
    "    x, y = 0, 0\n",
    "    features = get_image_features(img, x, y, x + 512, y + 512) #canto esquerdo sup.\n",
    "    features_list.append(features)\n",
    "\n",
    "    x, y = h-512, w-512\n",
    "    features = get_image_features(img, x, y, x + 512, y + 512) #canto direito inf.\n",
    "    features_list.append(features)\n",
    "\n",
    "    x, y = h, w\n",
    "    features = get_image_features(img, x-512, 0, x, 512) #canto direito sup.\n",
    "    features_list.append(features)\n",
    "\n",
    "    x, y = h, w\n",
    "    features = get_image_features(img, 0, y-512, 512, y) #canto esquerdo inf.\n",
    "    features_list.append(features)\n",
    "\n",
    "    x, y = h, w\n",
    "    startx = x//2-(512//2)\n",
    "    starty = y//2-(512//2)\n",
    "\n",
    "    features = get_image_features(img, startx, starty, startx + 512, starty+512) #centro\n",
    "    features_list.append(features)\n",
    "\n",
    "    features.update({\n",
    "        'device': os.path.basename(os.path.dirname(path)),\n",
    "        'filename': os.path.basename(path)\n",
    "    })\n",
    "    features_list.append(features)\n",
    "    return features_list\n",
    "\n",
    "def save_all_features(paths, output, verbose=False):\n",
    "    with open(output, 'w') as myfile:\n",
    "        for path in tqdm_notebook(paths):\n",
    "            features_list = get_path_features(path)\n",
    "            for features in features_list:\n",
    "                myfile.write(str(features))\n",
    "\n",
    "paths = ['train/Samsung-Galaxy-Note3/(GalaxyN3)54.jpg']\n",
    "save_all_features(paths, 'features.json', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features of 2750 images...\n",
      "Started at 2018-04-19 14:18:07.154022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b286b601e042aea17efb2ab6754fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2750), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p4w/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:2508: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/home/p4w/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:998: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "/home/p4w/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/p4w/.local/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/p4w/.local/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/p4w/.local/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/p4w/.local/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/p4w/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:998: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished at 2018-04-19 17:19:00.007707\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "paths = []\n",
    "base_dir = '/home/p4w/Documentos/mestrado/practical_assingments/pract_2/train'\n",
    "for device_dir in os.listdir(base_dir):\n",
    "    for file in os.listdir(os.path.join(base_dir, device_dir)):\n",
    "        paths.append(os.path.join(base_dir, device_dir, file))\n",
    "      \n",
    "print('Extracting features of {} images...'.format(len(paths)))\n",
    "print('Started at {}'.format(datetime.now()))\n",
    "save_all_features(paths, 'features.json')\n",
    "print('Finished at {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'denoise_wavelet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f89c2f3e15fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_wavelet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BayesShrink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdw_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m  \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise_dw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdw_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'denoise_wavelet' is not defined"
     ]
    }
   ],
   "source": [
    "dw = denoise_wavelet(img, multichannel=True, method='BayesShrink')\n",
    "dw_n = (dw  * 255).astype(np.int)\n",
    "noise_dw = img - dw_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 255), (0, 255), (0, 1))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img.min(), img.max()), (dw_n.min(), dw_n.max()), (noise_dw.min(), noise_dw.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(dw_n)\n",
    "ax3.imshow(noise_dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trailing data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-58a292439627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m             )\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 793\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Trailing data"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_json('features.csv')\n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aa0339794a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoises_mean\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train[df_train.noises_mean == 0].device.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.replace(np.inf, 0, inplace=True)\n",
    "df_train.replace(-np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3a706325fdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "features = df_train.columns.drop(['device', 'filename'])\n",
    "X = df_train[features].values\n",
    "y = df_train['device'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69181818 0.69763636 0.70963636 0.70054545 0.70772727] 0.7014727272727272\n",
      "CPU times: user 5min 12s, sys: 1.9 s, total: 5min 13s\n",
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "classifier = RandomForestClassifier(100, random_state=1986)\n",
    "\n",
    "cv = StratifiedKFold(5, True, 1986)\n",
    "scores = cross_val_score(classifier, X, y, scoring='accuracy', cv=cv)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-44209203a3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocal_binary_pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlocal_binary_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "local_binary_pattern(img, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
